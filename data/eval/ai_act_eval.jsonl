{"question": "What is the main objective of the EU AI Act?", "answer": "The main objective of the EU AI Act is to ensure the proper functioning of the internal market by establishing a uniform legal framework for the development, commercialization, and use of AI systems in the European Union. It aims to promote trustworthy, human-centric AI while ensuring a high level of protection of health, safety, fundamental rights, and the environment."}
{"question": "How does the AI Act define an AI system?", "answer": "The AI Act defines an AI system as a machine-based system designed to operate with varying levels of autonomy that can, for explicit or implicit objectives, generate outputs such as predictions, recommendations, or decisions influencing physical or virtual environments."}
{"question": "To whom does the AI Act apply?", "answer": "The AI Act applies to providers, deployers, importers, distributors, and manufacturers of AI systems placed on the EU market or whose outputs are used in the EU. It also applies to users outside the EU if their AI systems affect people located in the Union."}
{"question": "Which AI systems are prohibited under the AI Act?", "answer": "The AI Act prohibits AI systems that use subliminal techniques or exploit vulnerabilities to distort behavior, social scoring systems by public authorities, and remote biometric identification systems for law enforcement in real time in public spaces, except in specific narrowly defined cases."}
{"question": "What is considered a high-risk AI system under the AI Act?", "answer": "High-risk AI systems are those that pose significant risks to health, safety, or fundamental rights and are listed in Annex III of the Act, including systems used in biometric identification, critical infrastructure, education, employment, essential services, law enforcement, migration control, and justice."}
{"question": "What obligations must providers of high-risk AI systems fulfill?", "answer": "Providers of high-risk AI systems must implement risk management, ensure data governance quality, maintain technical documentation, establish logging capabilities, provide transparency to users, enable human oversight, and guarantee robustness, accuracy, and cybersecurity before placing the system on the market."}
{"question": "What obligations do deployers of high-risk AI systems have?", "answer": "Deployers of high-risk AI systems must use the systems according to instructions, ensure human oversight, monitor performance, maintain logs, and report serious incidents to providers or authorities."}
{"question": "What are the requirements for training data of high-risk AI systems?", "answer": "Training, validation, and testing data for high-risk AI systems must be relevant, representative, free of errors, and sufficiently complete to avoid bias, ensuring safety and respect of fundamental rights."}
{"question": "How does the AI Act regulate general-purpose AI (GPAI) models?", "answer": "Providers of general-purpose AI models must comply with transparency obligations, including documentation, dataset descriptions, copyright compliance, and information enabling responsible use. For systemic-risk GPAI models, stricter risk-mitigation and cybersecurity requirements apply."}
{"question": "What documentation must GPAI model providers make available?", "answer": "Providers of GPAI models must publish a detailed description of training data, system capabilities and limitations, evaluation results, model architecture overview, and recommended uses and restrictions."}
{"question": "Does the AI Act apply to AI systems used for purely personal activities?", "answer": "No. The AI Act does not apply to natural persons using AI systems strictly for personal, non-professional activities."}
{"question": "What obligations apply to importers of AI systems?", "answer": "Importers must ensure that AI systems from third countries comply with the AI Act, verify CE marking, ensure technical documentation availability, and refrain from placing non-compliant systems on the EU market."}
{"question": "What is the conformity assessment for high-risk AI systems?", "answer": "Conformity assessment verifies that a high-risk AI system meets all regulatory requirements before being placed on the market, including risk management, data quality, documentation, human oversight, and cybersecurity."}
{"question": "What are post-market monitoring obligations for providers?", "answer": "Providers must maintain a post-market monitoring system, collect and analyze real-world performance data, identify malfunctions or risks, and take corrective actions when needed."}
{"question": "When must a serious incident involving a high-risk AI system be reported?", "answer": "A serious incident must be reported by deployers or providers to competent authorities no later than 15 days after becoming aware of it."}
{"question": "What information must be provided to users of high-risk AI systems?", "answer": "Users must receive clear instructions for use, expected system performance, risks, required human oversight, and technical limitations."}
{"question": "Which transparency obligations apply to emotion-recognition systems?", "answer": "Users of emotion-recognition and biometric categorization systems must inform individuals when they are exposed to such AI systems, ensuring transparency and respect for fundamental rights."}
{"question": "How does the AI Act regulate AI systems used in law enforcement?", "answer": "AI systems used in law enforcement are subject to strict conditions, including high-risk classification, enhanced oversight, mandatory documentation, human supervision, and limitations on biometric identification in public spaces."}
{"question": "What purpose do regulatory sandboxes serve in the AI Act?", "answer": "Regulatory sandboxes allow providers to test innovative AI systems in real-world conditions under the supervision of authorities, ensuring compliance while fostering innovation."}
{"question": "What penalties apply for violations of the AI Act?", "answer": "Fines can range from EUR 7.5 million or 1% of global turnover to EUR 35 million or 7% of turnover, depending on the severity of the violation, such as using prohibited AI systems or failing documentation obligations."}
{"question": "What obligations apply to biometric identification systems?", "answer": "Such systems must comply with strict data quality, transparency, human oversight, cybersecurity, and accuracy requirements and are classified as high-risk, except when prohibited as real-time remote identification."}
{"question": "What rights do individuals have regarding AI systems that affect them?", "answer": "Individuals have the right to meaningful information about AI interactions, the right to contest decisions influenced by AI, and the right to lodge complaints with supervisory authorities."}
{"question": "When does the AI Act become fully applicable?", "answer": "The AI Act becomes progressively applicable starting in 2025, with full enforcement for most high-risk AI obligations by 2026â€“2027 and GPAI rules applied shortly thereafter."}
{"question": "How does the AI Act define a provider?", "answer": "A provider is a natural or legal person who develops or has an AI system developed and places it on the market or puts it into service under their name or trademark."}
{"question": "How does the AI Act ensure human oversight of AI systems?", "answer": "The Act requires that high-risk systems be designed to allow effective human supervision, enabling humans to understand, interpret, and override outputs when necessary."}
